<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Hao Kang's Personal Website">
  <meta name="keywords" content="Hao Kang, Georgia Tech, Deep Learning, Systems">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Hao Kang</title>

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Hao Kang (康浩)</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://scholar.google.com/citations?user=QI96hfoAAAAJ&hl=en" style="color: blue;">Chenyu Wang</a><sup>1,*</sup>,</span>
            <span class="author-block"><a href="https://zishenwan.github.io/" style="color: blue;">Zishen Wan</a><sup>2,*</sup>,</span>
            <span class="author-block"><a href="https://haokang-timmy.github.io/" style="color: blue;">Hao Kang</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=89ANml4AAAAJ&hl=en" style="color: blue;">Emma Chen</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://zhiqiangxie.com/" style="color: blue;">Zhiqiang Xie</a><sup>3</sup>,</span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="mailto:hao.kang.sys@gmail.com" class="external-link button is-medium is-rounded is-link">
                  <span class="icon"><i class="fas fa-envelope"></i></span>
                  <span>Email</span>
                </a>
                  </span>
              <span class="link-block">
                <a href="data/kh_cv10.15.pdf" class="external-link button is-medium is-rounded is-link">
                  <span class="icon"><i class="ai ai-cv"></i></span>
                  <span>CV</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/HaoKang-Timmy" class="external-link button is-medium is-rounded is-link">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Github</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="columns is-centered">
            <div class="column is-one-third">
                <img src="images/43510722.png" alt="profile photo" style="border-radius: 10px;"/>
            </div>
            <div class="column is-two-thirds content">
                <h2 class="title is-3">About Me</h2>
                <p>
                    I am a PhD student at Georgia Institute of Technology advised by Prof. Tushar Krishna. Prior to GT, I was fortunate to have worked with Prof Baharan at UCLA about efficient machine learning from massive datasets. At MIT, I work with Prof Song Han about efficient machine learning on edge device. I received my B.Eng. in Computer Science in 2023 from Zhejiang University.
                </p>
            </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
                <h2 class="title is-3 has-text-centered">Research Interests</h2>
        <div class="content has-text-left">
                <p>
                    I am interested in efficient machine learning and systems, experienced in the intersection of both field. I aim to use low-rank approximation and compression algorithms to accelerate machine learning models especially LLMs. Also, I design efficient systems like inference/fine-tuning scheduler to accelerate training/inference process.
                </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Publications</h2>
    
    <div class="publication-item">
        <div class="columns">
            <div class="column is-10 is-offset-1">
                <div class="content">
                    <h4 class="title is-4"><a href="https://arxiv.org/abs/2403.05527">GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM</a></h4>
                    <p><strong>Hao Kang*</strong>, Qingru Zhang*, Souvik Kundu, Geonhwa Jeong, Zaoxing Liu, Tushar Krishna, Tuo Zhao</p>
                    <p><em>Arxiv</em></p>
                    <p>We propose a novel cache compression algorithm on KV cache for large language model inference. It can achieve near-lossless compression ratio and 2x speedup and 2x peak memory saving on inference time.</p>
                </div>
            </div>
        </div>
        </div>
        
    <div class="publication-item">
        <div class="columns">
            <div class="column is-10 is-offset-1">
                <div class="content">
                    <h4 class="title is-4">KV Cache Optimizations for Large Language Model Inference</h4>
                    <p>In review <em>Mlsys2024</em></p>
                </div>
            </div>
        </div>
    </div>
    
    <div class="publication-item">
        <div class="columns">
            <div class="column is-10 is-offset-1">
                <div class="content">
                    <h4 class="title is-4"><a href="https://arxiv.org/pdf/2306.01244.pdf">Towards Sustainable Learning: Coresets for Data-efficient Deep Learning</a></h4>
                    <p>Yu Yang, <strong>Hao Kang</strong>, Baharan Mirzasoleiman</p>
                    <p><em>ICML 2023</em></p>
                    <p>We design a dataset distiling algorithm based on submodular function and batch SGD that can distil a small dataset from a large dataset. The small dataset can be used to train a model with similar performance to the model trained on the large dataset.</p>
                </div>
        </div>
      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Research Project and Tools</h2>
        
        <div class="project-item">
            <div class="columns">
                <div class="column is-10 is-offset-1">
                    <div class="content">
                        <h4 class="title is-4"><a href="https://github.com/HaoKang-Timmy/torchanalyse.git">torchanalyse.</a></h4>
                        <p>A model profiling tool based on TVM and Maestro(Thanks for the help Abhi!). It can profile the model and give the flops, memory usage, and latency of each layer. It can also give the flops of each operator in the model. <a href="data/Epipe.key">More Information</a></p>
                    </div>
                </div>
            </div>
        </div>

        <div class="project-item">
            <div class="columns">
                <div class="column is-10 is-offset-1">
                    <div class="content">
                        <h4 class="title is-4"><a href="https://github.com/HaoKang-Timmy/Epipe">Epipe: Efficient Pipeline Parallelism with Compression Algorithms.</a></h4>
                        <p>A research project based on Gpipe and low-rank approximation which decreases bandwidth of activation transfer during cloud-based training process. <a href="data/Epipe.key">More Information</a></p>
                    </div>
                </div>
            </div>
        </div>

        <div class="project-item">
            <div class="columns">
                <div class="column is-10 is-offset-1">
                    <div class="content">
                        <h4 class="title is-4"><a href="https://github.com/Lyken17/pytorch-OpCounter">THOP: PyTorch-OpCounter.</a></h4>
                        <p>A python third party library that counts flops of models(pytorch, jit, onnx). Already has 4k stars! I wrote the counter of onnx form. <a href="https://github.com/Lyken17/pytorch-OpCounter/pull/143">More Information</a></p>
                    </div>
        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
        Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
      </p>
    </div>
  </div>
</footer>

</body>
</html>
